@article{fowl_preventing_2021,
 abstract = {Large organizations such as social media companies continually release data, for example user images. At the same time, these organizations leverage their massive corpora of released data to train proprietary models that give them an edge over their competitors. These two behaviors can be in conflict as an organization wants to prevent competitors from using their own data to replicate the performance of their proprietary models. We solve this problem by developing a data poisoning method by which publicly released data can be minimally modified to prevent others from train-ing models on it. Moreover, our method can be used in an online fashion so that companies can protect their data in real time as they release it.We demonstrate the success of our approach onImageNet classification and on facial recognition.},
 archiveprefix = {arXiv},
 author = {Fowl, Liam and Chiang, Ping-yeh and Goldblum, Micah and Geiping, Jonas and Bansal, Arpit and Czaja, Wojtek and Goldstein, Tom},
 eprint = {2103.02683},
 eprinttype = {arxiv},
 journal = {arXiv:2103.02683 [cs]},
 keywords = {Computer Science - Cryptography and Security,Computer Science - Machine Learning},
 month = {February},
 primaryclass = {cs},
 shorttitle = {Preventing Unauthorized Use of Proprietary Data},
 title = {Preventing Unauthorized Use of Proprietary Data: Poisoning for Secure Dataset Release},
 url = {http://arxiv.org/abs/2103.02683},
 urldate = {2021-03-05},
 year = {2021}
}

